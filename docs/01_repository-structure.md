# Repository Structure & Design Philosophy

The repository follows a clean, modular structure designed to separate the distinct phases of building an LLM.

---

## ğŸ—‚ï¸ Repository Layout (High-Level)

```text
.
â”œâ”€â”€ data/               # Datasets and preprocessing artifacts
â”œâ”€â”€ src/                # Core implementation code (Engine Room)
â”‚   â”œâ”€â”€ config/         # Configuration files
â”‚   â”œâ”€â”€ tokenization/   # Tokenizer implementations
â”‚   â”œâ”€â”€ model/          # GPT / Transformer architecture code
â”‚   â”œâ”€â”€ training/       # Training loops, loss functions
â”‚   â”œâ”€â”€ evaluation/     # Metrics and analysis
â”‚   â”œâ”€â”€ utils/          # Logging, seeding, checkpoints
â”‚   â””â”€â”€ main.py         # Entry point
â”œâ”€â”€ notebooks/          # Exploratory notebooks and experiments
â””â”€â”€ README.md           # This file
```

---

## Folder Guide

| Folder | Purpose |
| :--- | :--- |
| **`src/`** | The "engine room". Contains pure, reusable Python modules. |
| **`notebooks/`** | Jupyter notebooks for interactive learning, data inspection, and visual debugging. |
| **`data/`** | Stores raw text data and processed `.bin` files. |

### `src/` Detailed Structure

```text
src/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model_config.py        # Model hyperparameters
â”‚   â”œâ”€â”€ training_config.py     # Training-related configs
â”‚   â””â”€â”€ tokenizer_config.py    # Tokenizer settings
â”œâ”€â”€ tokenization/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ bpe.py                 # Byte Pair Encoding implementation
â”‚   â”œâ”€â”€ vocab.py               # Vocabulary handling
â”‚   â””â”€â”€ tokenizer.py           # High-level tokenizer interface
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py          # Token + positional embeddings
â”‚   â”œâ”€â”€ attention.py           # Self-attention & multi-head attention
â”‚   â”œâ”€â”€ feedforward.py         # FFN blocks
â”‚   â”œâ”€â”€ transformer_block.py   # GPT block
â”‚   â””â”€â”€ gpt.py                 # Full GPT model
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py             # Dataset & dataloader logic
â”‚   â”œâ”€â”€ loss.py                # Cross-entropy, etc.
â”‚   â”œâ”€â”€ optimizer.py           # Optimizer setup
â”‚   â”œâ”€â”€ scheduler.py           # Learning rate schedulers
â”‚   â””â”€â”€ trainer.py             # Training loop
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py             # Perplexity, loss tracking
â”‚   â””â”€â”€ generation.py          # Text generation & sampling
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ seed.py                # Reproducibility
â”‚   â”œâ”€â”€ logging.py             # Lightweight logging
â”‚   â””â”€â”€ checkpoint.py          # Save / load model state
â””â”€â”€ main.py                    # Entry point (train / eval switch)
```

---

## Design Principles

1.  **Modularity**: Each folder encapsulates a specific domain of the problem.
2.  **Traceability**: The structure mirrors the learning path.
3.  **Simplicity**: Modules are organized to support reuse.


As the project grows, this structure may evolve (e.g., moving core logic into a `src/` package).

