{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a8c949",
   "metadata": {},
   "source": [
    "# My Exercise Solutions: Chapter 2 (Working with Text Data)\n",
    "\n",
    "**Date**: February 3, 2026\n",
    "\n",
    "**My goal**: I want to practice the Chapter 2 exercises in my own words and code to strengthen intuition about tokenization, vocab building, and data preparation.\n",
    "\n",
    "**Zero-copy note**: This notebook is my personal synthesis. I am not copying the source-material solutions.\n",
    "\n",
    "**Attribution**: Concepts are based on *Build a Large Language Model From Scratch* by Sebastian Raschka.\n",
    "\n",
    "**Scope note**: This notebook currently covers Exercises 2.1â€“2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8881b5",
   "metadata": {},
   "source": [
    "## Environment Check\n",
    "I want to record package versions for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bc8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8defe",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "I set seeds so I can reproduce results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9e6f2",
   "metadata": {},
   "source": [
    "## Exercise 2.1\n",
    "**Prompt (my words)**: Explore how the GPT-2 BPE tokenizer splits the string \"Akwirw ier\" and interpret the token IDs and decoded pieces.\n",
    "\n",
    "**My approach**: Use `tiktoken` to encode the string, print the token IDs, decode each token, and probe a few substrings to see where merges happen.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "text = \"Akwirw ier\"\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "encoded = tokenizer.encode(text)\n",
    "\n",
    "print(\"Text:\", text)\n",
    "print(\"Token IDs:\", encoded)\n",
    "print(\"Decoded pieces:\")\n",
    "for token_id in encoded:\n",
    "    print(f\"  {token_id} -> {tokenizer.decode([token_id])}\")\n",
    "\n",
    "print(\"Reconstructed:\", tokenizer.decode(encoded))\n",
    "\n",
    "probe_strings = [\"Ak\", \"w\", \"ir\", \" \", \"ier\"]\n",
    "print(\"\\nSubstring probes:\")\n",
    "for snippet in probe_strings:\n",
    "    print(f\"  {snippet!r} -> {tokenizer.encode(snippet)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ff858",
   "metadata": {},
   "source": [
    "## Exercise 2.2\n",
    "**Prompt (my words)**: Build a minimal GPT-style dataset and dataloader with a sliding window, then inspect a few batches using small `max_length` and `stride` values.\n",
    "\n",
    "**My approach**: Rebuild a simple `Dataset` class, load `the-verdict.txt`, create dataloaders with different window sizes, and print the first batch.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35884cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a minimal Dataset + DataLoader\n",
    "# TODO: Create batches with different max_length/stride values\n",
    "# TODO: Inspect x/y pairs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-from-scratch-practice (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
